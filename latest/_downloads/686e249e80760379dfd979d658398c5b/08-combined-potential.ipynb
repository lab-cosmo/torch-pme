{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Optimizing a linear combination of potentials\n\n.. currentmodule:: torchpme\n\n:Authors: Egor Rumiantsev [@E-Rum](https://github.com/E-Rum/);\n   Philip Loche [@PicoCentauri](https://github.com/PicoCentauri)\n\nThis is an example to demonstrate the usage of the :class:`CombinedPotential` class to\nevaluate potentials that combine multiple pair potentials with optimizable ``weights``.\n\nWe will optimize the ``weights`` to reporoduce the energy of a system that\ninteracts solely via Coulomb interactions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import ase.io\nimport chemiscope\nimport matplotlib.pyplot as plt\nimport torch\nfrom vesin.torch import NeighborList\n\nfrom torchpme import CombinedPotential, EwaldCalculator, InversePowerLawPotential\nfrom torchpme.prefactors import eV_A\n\ndtype = torch.float64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Combined potentials\n\nWe load the small :download:`dataset <coulomb_test_frames.xyz>` that contains eight\nrandomly placed point charges in a cubic cell of different cell sizes. Each structure\ncontains four positive and four negative charges that interact via a Coulomb\npotential.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "frames = ase.io.read(\"coulomb_test_frames.xyz\", \":\")\n\nchemiscope.show(\n    frames=frames,\n    mode=\"structure\",\n    settings=chemiscope.quick_settings(\n        structure_settings={\"unitCell\": True, \"bonds\": False}\n    ),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We choose half of the box length as the ``cutoff`` for the neighborlist and also\ndeduce the other parameters from the first frame.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cutoff = frames[0].cell.array[0, 0] / 2 - 1e-6\nsmearing = cutoff / 6.0\nlr_wavelength = 0.25 * smearing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now construct the potential as sum of two :class:`InversePowerLawPotential` using\n:class:`CombinedPotential`. The presence of a numerical `smearing` value is used as an\nindication that the potential can compute the terms needed for range-separated\nevaluation, and so one has to set it also for the combined potential, even if it is\nnot used explicitly in the evaluation of the combination.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pot_1 = InversePowerLawPotential(exponent=1, smearing=smearing)\npot_2 = InversePowerLawPotential(exponent=2, smearing=smearing)\npot_1 = pot_1.to(dtype=dtype)\npot_2 = pot_2.to(dtype=dtype)\npotential = CombinedPotential(potentials=[pot_1, pot_2], smearing=smearing)\npotential = potential.to(dtype=dtype)\n\n# Note also that :class:`CombinedPotential` can be used with any combination of\n# potentials, as long they are all either direct or range separated. For instance, one\n# can combine a :class:`CoulombPotential` and a :class:`SplinePotential`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plotting terms in the potential\nWe now plot of the individual and combined ``potential`` functions together with an\nexplicit sum of the two potentials.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dist = torch.logspace(-3, 2, 1000, dtype=dtype)\n\nfig, ax = plt.subplots()\n\nax.plot(dist, pot_1.from_dist(dist), label=\"p=1\")\nax.plot(dist, pot_2.from_dist(dist), label=\"p=2\")\n\nax.plot(dist, potential.from_dist(dist).detach(), label=\"Combined potential\", c=\"black\")\nax.plot(\n    dist,\n    pot_1.from_dist(dist) + pot_2.from_dist(dist),\n    label=\"Explict combination\",\n    ls=\":\",\n)\n\nax.set(\n    xlabel=\"Distance\", ylabel=\"Potential\", xscale=\"log\", yscale=\"log\", xlim=[1e-3, 1e2]\n)\n\nax.legend()\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the *log-log* plot we see that the $p=2$ potential (orange) decays much\nfaster compared to the $p=1$ potential (blue). We also verify that the combined\npotential (black) is the sum of the two potentials that we explicitly calculated\n(dotted green line).\n\nThe :class:`CombinedPotential` class\ncombines all terms in a range-separated potential, including the k-space\nkernel.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "k = torch.logspace(-2, 2, 1000, dtype=dtype)\n\nfig, ax = plt.subplots()\n\nax.plot(dist, pot_1.lr_from_k_sq(k**2), label=\"p=1\")\nax.plot(dist, pot_2.lr_from_k_sq(k**2), label=\"p=2\")\n\nax.plot(\n    dist, potential.lr_from_k_sq(k**2).detach(), label=\"Combined potential\", c=\"black\"\n)\nax.plot(\n    dist,\n    pot_1.lr_from_k_sq(k**2) + pot_2.lr_from_k_sq(k**2),\n    label=\"Explict combination\",\n    ls=\":\",\n)\n\nax.set(\n    xlabel=r\"$|\\mathbf{k}|$\",\n    ylabel=\"Potential\",\n    xscale=\"log\",\n    yscale=\"log\",\n    xlim=[1e-2, 1e1],\n    ylim=[1e-10, 1e4],\n)\n\nax.legend()\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimizing the mixing weights\nWe next construct the calculator. Note that below we use the :class:`EwaldCalculator`\nbut one can of course also use the :class:`PMECalculator` if one wants to optimize a\nmuch bigger system.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "calculator = EwaldCalculator(\n    potential=potential, lr_wavelength=lr_wavelength, prefactor=eV_A\n)\ncalculator.to(dtype=dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To save some time during optimization we precompute the neighborlist and store all\nvalues in convient lists. We store the data in lists of torch tensors because in\ngeneral the number of particles in each frame can be different.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "nl = NeighborList(cutoff=cutoff, full_list=False)\n\nl_positions = []\nl_cell = []\nl_charges = []\nl_neighbor_indices = []\nl_neighbor_distances = []\nl_ref_energy = torch.zeros(len(frames))\n\nfor i_atoms, atoms in enumerate(frames):\n    positions = torch.from_numpy(atoms.positions)\n    cell = torch.from_numpy(atoms.cell.array)\n    charges = torch.from_numpy(atoms.get_initial_charges()).reshape(-1, 1)\n\n    p, d = nl.compute(points=positions, box=cell, periodic=True, quantities=\"Pd\")\n\n    l_positions.append(positions)\n    l_cell.append(cell)\n    l_charges.append(charges)\n\n    l_neighbor_indices.append(p)\n    l_neighbor_distances.append(d)\n\n    l_ref_energy[i_atoms] = atoms.get_potential_energy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Definition of loss and optimizer\nFor the optimization we define two functions that compute the energy of all structures and\nthe mean squared error of the energy with respect to the reference values as loss.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def compute_energy() -> torch.Tensor:\n    \"\"\"Compute the energy of all structures using a globally defined `calculator`.\"\"\"\n    energy = torch.zeros(len(frames))\n    for i_atoms in range(len(frames)):\n        charges = l_charges[i_atoms]\n\n        potential = calculator(\n            charges=charges,\n            cell=l_cell[i_atoms],\n            positions=l_positions[i_atoms],\n            neighbor_indices=l_neighbor_indices[i_atoms],\n            neighbor_distances=l_neighbor_distances[i_atoms],\n        )\n        energy[i_atoms] = (charges * potential).sum()\n\n    return energy\n\n\ndef loss() -> torch.Tensor:\n    \"\"\"Compute the mean squared error of the energy.\"\"\"\n    energy = compute_energy()\n    mse = torch.sum((energy - l_ref_energy) ** 2)\n    return mse.sum()\n\n\noptimizer = torch.optim.Adam(calculator.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Running the optimization\nWe now optimize the weights of the potentials to minimize the mean squared error using\nthe :class:`torch.optim.Adam` optimizer and stop either after 1000 epochs or when the\nloss is smaller than $10^{-2}$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "weights_timeseries = []\nloss_timeseries = []\n\nfor _ in range(1000):\n    optimizer.zero_grad()\n\n    loss_value = loss()\n    loss_value.backward()\n    optimizer.step()\n\n    loss_timeseries.append(float(loss_value.detach().cpu()))\n    weights_timeseries.append(calculator.potential.weights.detach().cpu().tolist())\n\n    if loss_value < 1e-4:\n        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can show the evolution of the weights during the optimization. The weights for\nthe $1/r$ and $1/r^2$ potentials converge towards $1$ and $0$,\nrespectively. This is the expected behavior, since the reference potential used to\ncompute the energy of the structures includes only a Coulombic term.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n\nax.axhline(1, c=\"blue\", ls=\"dotted\", label=\"expected weight p=1\")\nax.axhline(0, c=\"orange\", ls=\"dotted\", label=\"expected weight p=2\")\n\nweights_timeseries_array = torch.tensor(weights_timeseries)\n\nax.plot(weights_timeseries_array[:, 0], label=\"p=1\", c=\"blue\")\nax.plot(weights_timeseries_array[:, 1], label=\"p=2\", c=\"orange\")\n\nax.set(\n    ylim=(-0.2, 1.2),\n    xlabel=\"Learning epoch\",\n    ylabel=\"Mixing weights\",\n    xscale=\"log\",\n)\n\nax.legend()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}